## ğŸ Hey â€” Iâ€™m Alex 
I'm a PhD candidate probing how neural networks think so we can build safer, better-aligned AI.

### ğŸ”­ What Iâ€™m up to
- **Writing up** my PhD thesis on _Interpretable Representations in Artificial Neural Networks_.
- **Doing Research** on technical alignment - see [my scholar page](https://www.semanticscholar.org/author/Alex-F-Spies/144807908).
- **Working** as a research-engineering intern at Epic Games â€” scaling & fine-tuning LLMs for creative tools.  
- **Procrastinating** with Side projects:
  - [AI-Safety-Papers](https://github.com/afspies/ai-safety-papers) â€” a living reading-list with concise notes.)
  - 
### ğŸŒ Elsewhere
[Website](https://afspies.com)â€‚| [Twitter/X @afspies](https://twitter.com/afspies)â€‚|â€‚[LinkedIn](https://linkedin.com/in/afspies)â€‚|â€‚âœ‰ï¸ alex [at] afspies (dot) com

